{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4405a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import system libs\n",
    "import time\n",
    "import shutil\n",
    "import pathlib\n",
    "import itertools\n",
    "# import data handling tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print ('modules loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.utils import load_img\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from keras.applications.mobilenet_v3 import MobileNetV3\n",
    "from keras.applications.mobilenet_v3 import preprocess_input\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras import metrics\n",
    "from keras import Model, layers\n",
    "from keras.callbacks import *\n",
    "from keras.models import load_model, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "parasitized_data = os.listdir('E:/Personal Files/Dr. Shafique Awan/Thesis/malaria-parasite-detection/cell-images-for-detecting-malaria/cell_images/Parasitized/')\n",
    "uninfected_data = os.listdir('E:/Personal Files/Dr. Shafique Awan/Thesis/malaria-parasite-detection/cell-images-for-detecting-malaria/cell_images/Uninfected/')\n",
    "#print(parasitized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(title,directory):\n",
    "    print(title)\n",
    "    plt.figure(figsize = (12,12))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        img = cv2.imread( directory+ \"/\" + parasitized_data[i])\n",
    "        #print(img)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB));\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "plotImages(\"Images of malaria infected cells\",\"E:/Personal Files/Dr. Shafique Awan/Thesis/malaria-parasite-detection/cell-images-for-detecting-malaria/cell_images/Parasitized\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(title,directory):\n",
    "    print(title)\n",
    "    plt.figure(figsize = (12,12))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        img = cv2.imread( directory+ \"/\" + uninfected_data[i])\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "plotImages(\"Images of Uninfected cells\",\"E:/Personal Files/Dr. Shafique Awan/Thesis/malaria-parasite-detection/cell-images-for-detecting-malaria/cell_images/Uninfected\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = \"E:/Personal Files/Dr. Shafique Awan/Thesis/malaria-parasite-detection/cell-images-for-detecting-malaria/\"\n",
    "\n",
    "PATH = os.path.sep.join([workingDir, \"cell_images\"])\n",
    "\n",
    "# Getting the path ot the training directory \n",
    "train_dir = os.path.join(workingDir, \"cell_images\")\n",
    "\n",
    "# Getting the path to the validation directory \n",
    "validation_dir = os.path.join(workingDir, \"cell_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parasitized_train_dir = os.path.join(train_dir, \"Parasitized\")\n",
    "uninfected_train_dir = os.path.join(train_dir, \"Uninfected\")\n",
    "\n",
    "print(parasitized_train_dir)\n",
    "# Getting the path to the directory for the parasitized validation cell images and \n",
    "# the path to the directory for the uninfected validation cell images \n",
    "parasitized_val_dir = os.path.join(validation_dir, \"Parasitized\") \n",
    "uninfected_val_dir = os.path.join(validation_dir, \"Uninfected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the number of images present in the parasitized training directory and the \n",
    "# number of images present in the uninfected training directory \n",
    "parasitized_images = len(os.listdir(parasitized_train_dir))\n",
    "uninfected_images = len(os.listdir(uninfected_train_dir))\n",
    "\n",
    "# Getting the number of images present in the parasitized validation directory and the \n",
    "# number of images present in the uninfected validation directory \n",
    "parasitized_images_val = len(os.listdir(parasitized_val_dir)) \n",
    "uninfected_images_val = len(os.listdir(uninfected_val_dir)) \n",
    "\n",
    "# Getting the sum of both the training images and validation images \n",
    "total_train = parasitized_images + uninfected_images  \n",
    "total_val = parasitized_images_val + uninfected_images_val \n",
    "\n",
    "# Displaying the results for Training images  \n",
    "print(\"Total Training parasitized images: {}\".format(parasitized_images)); \n",
    "print(\"Total Training uninfected images: {}\".format(uninfected_images)); \n",
    "print(\"__________________________________________________________________________________________________________\\n\");\n",
    "\n",
    "# Displaying the results for Validation images  \n",
    "print(\"Total Validation parasitized images: {}\".format(parasitized_images_val)); \n",
    "print(\"Total Validation uninfected images: {}\".format(uninfected_images_val)); \n",
    "print(\"__________________________________________________________________________________________________________\\n\"); \n",
    "\n",
    "# Displaying the total values for the images in both the training and validation directory \n",
    "print(\"Total Train: {}\".format(total_train)); \n",
    "print(\"Total Validation: {}\".format(total_val)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20 \n",
    "IMG_HEIGHT = 110 \n",
    "IMG_WIDTH = 110\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                    #color_mode=\"grayscale\",\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    shuffle = True\n",
    "                                                   )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(directory = validation_dir,\n",
    "                                                  target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 # color_mode=\"grayscale\",\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = 'binary',\n",
    "                                                  shuffle = True\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def conv2d_bn(x, filters, kernel_size, weight_decay=.0, strides=(1, 1)):\n",
    "    layer = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same',\n",
    "                   use_bias=False,\n",
    "                   kernel_regularizer=l2(weight_decay)\n",
    "                   )(x)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def conv2d_bn_relu(x, filters, kernel_size, weight_decay=.0, strides=(1, 1)):\n",
    "    layer = conv2d_bn(x, filters, kernel_size, weight_decay, strides)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def ResidualBlock(x, filters, kernel_size, weight_decay, downsample=True):\n",
    "    if downsample:\n",
    "        # residual_x = conv2d_bn_relu(x, filters, kernel_size=1, strides=2)\n",
    "        residual_x = conv2d_bn(x, filters, kernel_size=1, strides=2)\n",
    "        stride = 2\n",
    "    else:\n",
    "        residual_x = x\n",
    "        stride = 1\n",
    "    residual = conv2d_bn_relu(x,\n",
    "                              filters=filters,\n",
    "                              kernel_size=kernel_size,\n",
    "                              weight_decay=weight_decay,\n",
    "                              strides=stride,\n",
    "                              )\n",
    "    residual = conv2d_bn(residual,\n",
    "                         filters=filters,\n",
    "                         kernel_size=kernel_size,\n",
    "                         weight_decay=weight_decay,\n",
    "                         strides=1,\n",
    "                         )\n",
    "    out = layers.add([residual_x, residual])\n",
    "    out = Activation('relu')(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResNet18(classes, input_shape, weight_decay=1e-4):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = input\n",
    "    # x = conv2d_bn_relu(x, filters=64, kernel_size=(7, 7), weight_decay=weight_decay, strides=(2, 2))\n",
    "    # x = MaxPool2D(pool_size=(3, 3), strides=(2, 2),  padding='same')(x)\n",
    "    x = conv2d_bn_relu(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, strides=(1, 1))\n",
    "\n",
    "    # # conv 2\n",
    "    x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
    "    x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
    "    # # conv 3\n",
    "    x = ResidualBlock(x, filters=128, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n",
    "    x = ResidualBlock(x, filters=128, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
    "    # # conv 4\n",
    "    x = ResidualBlock(x, filters=256, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n",
    "    x = ResidualBlock(x, filters=256, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
    "    # # conv 5\n",
    "    x = ResidualBlock(x, filters=512, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n",
    "    x = ResidualBlock(x, filters=512, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
    "    x = AveragePooling2D(pool_size=(4, 4), padding='valid')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='sigmoid')(x)\n",
    "    model = Model(input, x, name='ResNet18')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import optimizers\n",
    "\n",
    "weight_decay = 1e-4\n",
    "lr = 1e-1\n",
    "num_classes = 1\n",
    "resnet18 = ResNet18(input_shape=(110, 110, 3), classes=num_classes, weight_decay=weight_decay)\n",
    "opt = optimizers.Adam(learning_rate=lr)\n",
    "resnet18.compile(optimizer=opt,\n",
    "                 loss=losses.binary_crossentropy,\n",
    "                 metrics=['accuracy'])\n",
    "resnet18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the input data by using the fit_generator function \n",
    "history = resnet18.fit_generator(train_generator, steps_per_epoch = total_train // batch_size, \n",
    "                       epochs = epochs, \n",
    "                       validation_data = validation_generator, \n",
    "                       validation_steps = total_val // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45061587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50V2 pre-trained model\n",
    "\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "image_input_shape = Input(shape=(110, 110, 3))\n",
    "resnetv2 = ResNet50V2(input_tensor=image_input_shape, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0187129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not train the existing weights\n",
    "for layer in resnetv2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# defining input and output to the model\n",
    "x = Flatten()(resnetv2.output)\n",
    "prediction = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7296c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = resnetv2.input, outputs = prediction)\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042adeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "metrics = ['accuracy']\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the input data by using the fit_generator function \n",
    "history = model.fit_generator(train_generator, steps_per_epoch = total_train // batch_size, \n",
    "                       epochs = epochs, \n",
    "                       validation_data = validation_generator, \n",
    "                       validation_steps = total_val // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ce558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MobileNetV2 pre-trained model\n",
    "\n",
    "moblieNetV2 = MobileNetV2(\n",
    "    input_shape=[IMG_HEIGHT, IMG_WIDTH] + [1],\n",
    "    alpha=1.0,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\")\n",
    "\n",
    "# do not train the existing weights\n",
    "for layer in moblieNetV2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# defining input and output to the model\n",
    "x = Flatten()(moblieNetV2.output)\n",
    "prediction = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b189ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = moblieNetV2.input, outputs = prediction)\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942628db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the input data by using the fit_generator function \n",
    "history = model.fit_generator(train_generator, steps_per_epoch = total_train // batch_size, \n",
    "                       epochs = epochs, \n",
    "                       validation_data = validation_generator, \n",
    "                       validation_steps = total_val // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c1b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 pre-trained model\n",
    "\n",
    "inceptionV3=InceptionV3(input_shape=[IMG_HEIGHT, IMG_WIDTH] + [1],\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\")\n",
    "\n",
    "# do not train the existing weights\n",
    "for layer in inceptionV3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# defining input and output to the model\n",
    "x = Flatten()(inceptionV3.output)\n",
    "prediction = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a755a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = inceptionV3.input, outputs = prediction)\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea53871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "\n",
    "metrics = ['accuracy']\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the input data by using the fit_generator function \n",
    "history = model.fit_generator(train_generator, steps_per_epoch = total_train // batch_size, \n",
    "                       epochs = epochs, \n",
    "                       validation_data = validation_generator, \n",
    "                       validation_steps = total_val // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108d40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89966ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instantiating the VGG19 model\n",
    "# vgg19 = VGG19(input_shape=[IMG_HEIGHT, IMG_WIDTH] + [3],\n",
    "#                   weights='imagenet', # include the pre-trained weights on ImageNet\n",
    "#                   include_top=False)  # to use our own input and get the desired output\n",
    "\n",
    "# # do not train the existing weights\n",
    "# for layer in vgg19.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # defining input and output to the model\n",
    "# x = Flatten()(vgg19.output)\n",
    "# prediction = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a model object\n",
    "# model = Model(inputs = vgg19.input, outputs = prediction)\n",
    "\n",
    "# # view the structure of the model\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121dc29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tell the model what cost and optimization method to use\n",
    "\n",
    "# metrics = ['accuracy',\n",
    "#            metrics.Precision(name='precision'),\n",
    "#            metrics.Recall(name='recall')\n",
    "#           ]\n",
    "\n",
    "# model.compile(\n",
    "#   loss='binary_crossentropy',\n",
    "#   optimizer='adam',\n",
    "#   metrics=metrics\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the model on the input data by using the fit_generator function \n",
    "# history = model.fit_generator(train_generator, steps_per_epoch = total_train // batch_size, \n",
    "#                        epochs = epochs, \n",
    "#                        validation_data = validation_generator, \n",
    "#                        validation_steps = total_val // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065bf6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(history, lw = 3):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    \n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb39c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_performace = model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model for further uses \n",
    "modelName = \"MalariaModel.h5\" \n",
    "model.save_weights(modelName); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526699a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"E:/Personal Files/Dr. Shafique Awan/Thesis/malaria-parasite-detection/test/test/test1\"\n",
    "\n",
    "# Getting the first Four images \n",
    "ImgDir = list(os.listdir(img)) \n",
    "ImgDir = ImgDir[:3] \n",
    "\n",
    "# Loading Just a random image from the Parasitized images folder. \n",
    "imagePath = os.path.join(img, \"C39P4thinF_original_IMG_20150622_105803_cell_103.png\")\n",
    "\n",
    "# Displaying the full path to the parasitized image we want to use for prediction. \n",
    "print(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c346da",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imagePath); \n",
    "\n",
    "# Setting the dimensions for the loaded image to be converted into and displaying the shape of the image \n",
    "print(\"Loaded Image Shape: {}\".format(img.shape)); \n",
    "dim = (IMG_HEIGHT, IMG_WIDTH); \n",
    "\n",
    "# Resizing the image \n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA); \n",
    "plt.grid(False) \n",
    "plt.imshow(img) \n",
    "plt.show() \n",
    "\n",
    "# Expanding the image dimensions \n",
    "image = np.expand_dims(img, axis = 0); \n",
    "\n",
    "# Making Final Predictions \n",
    "result = model.predict(image)\n",
    "# Creating a loop to get the actual predicted class \n",
    "for key, value in (train_generator.class_indices.items()): \n",
    "    if value == result: \n",
    "        print(\"The Predicted Class is: {}\".format(key))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
